---
layout: projects
title: Predicting Energy Demand and Off-System Sales of CPS Energy
---

Code for this project can be found in my [repo](https://github.com/williamscale/projects/tree/main/ERCOT).

## Background

The goal of this project is to simulate the demand prediction and energy transaction process that CPS Energy engages in on a daily basis. Several assumptions have been made and are noted as such. I am not an expert in the field and, thus, some of the decisions made in the analysis may be flawed.

CPS is owned by the City of San Antonio and is responsible for its own customers and service area in the map below. Excess power generated by CPS can be sold via the ERCOT market. This revenue benefits CPS and its customers and is known as off-system sales. 

![ERCOT Zones](https://williamscale.github.io/attachments/cps-load-prediction/ERCOT-Maps_Load-Zone.jpg)

## Data

Daily CPS electricity demand data for 2024 was obtained via an open records request to CPS. A snippet of the raw data is shown below.

| Operating Day | Demand [MWh] |
|:-------------:|:------------:|
| 01/01/2024    | 54,296       |
| 01/02/2024    | 68,183       |
| &#8942;       | &#8942;      |
| 12/30/2024    | 55,599       |
| 12/31/2024    | 52,760       |

The distribution and data over time is shown below.

![Demand Histogram](https://williamscale.github.io/attachments/cps-load-prediction/demand_hist.png)

![Demand](https://williamscale.github.io/attachments/cps-load-prediction/demand_time.png)

A couple of new features were created based only on the date: **dayOfWeek** and **weekend.flag**. 

| Feature            | Type    | Description |
|:------------------:|:-------:|:------------|
| dayOfWeek          | factor  | Monday, Tuesday, etc. |
| weekend.flag       | T/F     | Saturday or Sunday |

My hypothesis was that energy demands in a city would be highly dependent on occupation status of offices vs. homes. The demand dataset then looks as such:

| Operating Day | Demand [MWh] | dayOfWeek | weekend.flag | 
|:-------------:|:------------:|:----------|:------------:|
| 01/01/2024    | 54,296       | Monday    | False        |
| 01/02/2024    | 68,183       | Tuesday   | False        |
| &#8942;       | &#8942;      | &#8942;   | &#8942;      |
| 12/30/2024    | 55,599       | Monday    | False        |
| 12/31/2024    | 52,760       | Tuesday   | False        |

Next, [NOAA's Online Weather Data](https://www.weather.gov/media/climateservices/NOWData.pdf) (NOWData) was [queried](https://www.weather.gov/wrh/Climate?wfo=ewx) for daily high and low temperatures [$^{\circ}$F] in the San Antonio area. A snippet of the weather data is shown below. It's important to recognize that these are actual temperatures, not forecasts. 

| operatingDay | Min [$^{\circ}$F] | Max [$^{\circ}$F] |
|:------------:|:-----------------:|:-----------------:|
| 1/1/2024     | 46                | 62                |
| 1/2/2024     | 44                | 49                |
| &#8942;      | &#8942;           | &#8942;           |
| 12/30/2024   | 46                | 89                |
| 12/31/2024   | 50                | 72                |

![Temps](https://williamscale.github.io/attachments/cps-load-prediction/sa_temps.png)

The demand and temperature datasets were then joined on **operatingDay**. The data was then split into training (80%), validation (10%), and testing sets (10%). The training set includes all data between January 1 and October 18 ($n=292$). The validation set is October 19 through November 24 ($n=37$) and the test set is November 25 through December 31 ($n=37$). Ordinarily, I would split the data randomly, but to keep things simpler for a time series analysis, I split it temporally. A snippet of the training set is shown below.

| operatingDay | dayOfWeek | weekend.flag | Min Temp | Max Temp | Demand  |
|:------------:|:----------|:------------:|:--------:|:--------:|:-------:|
| 01/01/2024   | Monday    | Weekday      | 46       | 62       | 54,296  |
| 01/02/2024   | Tuesday   | Weekday      | 44       | 49       | 68,183  |
| &#8942;      | &#8942;   | &#8942;      | &#8942;  | &#8942;  | &#8942; | 
| 10/17/2024   | Thursday  | Weekday      | 54       | 78       | 57,480  |
| 10/18/2024   | Friday    | Weekday      | 61       | 82       | 60,733  |

## Features

In this section, all analysis was done using the training set.

### Day of Week

Below are the demands by the day of the week. It is not immediately evident if there are any significant differences.

![Demand by Day of Week](https://williamscale.github.io/attachments/cps-load-prediction/dayOfWeek_jitter.png)

An Analysis of Variance (ANOVA) can be done to determine if there are differences. However, as shown below, the data is not normal and thus, ANOVA assumptions are violated and a nonparametric method must be used.

![Day of Week Histogram](https://williamscale.github.io/attachments/cps-load-prediction/dayOfWeek_hist.png)

![Day of Week QQ](https://williamscale.github.io/attachments/cps-load-prediction/dayOfWeek_qq.png)

Therefore, a Kruskal-Wallis test was performed and results imply there is not a statistically significant difference in demand by day of the week ($\text{p-value} = 0.77$) and it should not be included in the model.

### Weekday vs. Weekend

Similarly, below are the daily loads for weekdays and weekends. It is not obvious whether there is a significant difference between the two groups. Further investigation may be useful.

![Load by Weekend](https://williamscale.github.io/attachments/cps-load-prediction/weekend_jitter.png)

As shown below, the distributions of daily loads by weekday/weekend are not normal either. Thus, a two-sample t-test cannot be used and we opt for a two-sample Wilcoxon test.

![Weekend Histogram](https://williamscale.github.io/attachments/cps-load-prediction/weekend_hist.png)

![Weekend QQ](https://williamscale.github.io/attachments/cps-load-prediction/weekend_qq.png)

The $\text{p-value} = 0.10$, therefore we accept the null hypothesis that there is not a significant difference between weekdays and weekends at a significance level of $\alpha = 0.05$.

### Temperature

Below are the minimum and maximum daily temperatures plotted with the daily loads. It is evident that there is a relationship between the variables, albeit a non-linear one.

![Min vs. Load](https://williamscale.github.io/attachments/cps-load-prediction/min_demand_train.png)
![Histogram Min Temp](https://williamscale.github.io/attachments/cps-load-prediction/min_train_hist.png)

![Max vs. Load](https://williamscale.github.io/attachments/cps-load-prediction/max_demand_train.png)
![Histogram Max Temp](https://williamscale.github.io/attachments/cps-load-prediction/max_train_hist.png)

| Feature  | Min [$^{\circ}$F] | Max [$^{\circ}$F] | Mean [$^{\circ}$F] | Median [$^{\circ}$F] | Standard Deviation [$^{\circ}$F] |
|:--------:|:-----------------:|:-----------------:|:------------------:|:---------------------|:--------------------------------:|
| Min Temp | 18                | 81                | 65                 | 70                   | 14                               |
| Max Temp | 29                | 108               | 85                 | 89                   | 14                               |

Because the day of the week features were deemed not statistically significant, they are excluded from model building. Temperature with a quadratic term is thus the only feature so far. Because minimum and maximum temperatures are collinear (Pearson's correlation coefficient, $\rho = 0.89$), they cannot be used simultaneously in a model, and will be evaluated separately. 

## Model Building

### Linear Regression

#### Model 1.1: Minimum Temperature

This model was built on the training data as

$$
\text{Demand} = \beta_{0} + \beta_{1} \text{Min Temp} + \beta_{2} \text{Min Temp}^{2}
$$

where $\beta_{0} = 177,128$, $\beta_{1} = -4,876$, and $\beta_{2} = 49$. All coefficients are significant with $\text{p-values} \approx 0$ and adjusted $R^{2}=0.86$. The resulting regression line is shown below.

![Model 1](https://williamscale.github.io/attachments/cps-load-prediction/m1_reg.png)

#### Assumptions

Firstly, I checked for outliers using the Cook's distance metric. A data point exceeding a Cook's distance of 1 or $\frac{4}{n}$ where $n$ is the number of data points, should be investigated. These are two common rules of thumb, not hard rules. As shown below, there are a few points above the $\frac{4}{n}$ red line and one significantly larger than the rest of the dataset.

![CD Model 1](https://williamscale.github.io/attachments/cps-load-prediction/cd_m1.png)

From the fitted values vs. residuals plot below, we can see the constant variance and linearity assumptions are satisfied. The residuals are centered around 0 and there does not appear to be any heteroscedasticity. There may be some independence assumption deviation with potential clusters at the lower end of the fitted values. However, it doesn't seem too severe.

![Fitted vs. Residuals M1](https://williamscale.github.io/attachments/cps-load-prediction/fitted_resid_m1.png)

The normality assumption holds as shown by the histogram and QQ plots below.

![Hist Residuals M1](https://williamscale.github.io/attachments/cps-load-prediction/hist_resid_m1.png)

![QQ M1](https://williamscale.github.io/attachments/cps-load-prediction/qq_m1.png)

#### Model 1.2: Maximum Temperature

This model was built on the training data as

$$
\text{Demand} = \beta_{0} + \beta_{1} \text{Max Temp} + \beta_{2} \text{Max Temp}^{2}
$$

where $\beta_{0} = 262,651$, $\beta_{1} = -5,949$, and $\beta_{2} = 43$. All coefficients are significant with $\text{p-values} \approx 0$ and adjusted $R^{2}=0.87$. The resulting regression line is shown below.

![Model 2](https://williamscale.github.io/attachments/cps-load-prediction/m2_reg.png)

#### Assumptions

Outliers are checked via Cook's Distance as shown below.

![CD Model 2](https://williamscale.github.io/attachments/cps-load-prediction/cd_m2.png)

The highest points correspond to the days of the training set with much colder daily extreme temps than the rest of the data. Mid-January included the coldest days of the entire year. Removing some outliers may be considered. Ideally, more winter data would be available to determine how rare these cold days are.

From the fitted values vs. residuals plot below, we can see the constant variance and linearity assumptions are satisfied. The residuals are centered around 0 and there does not appear to be any heteroscedasticity. There may be some independence assumption deviation with potential clusters at the lower end of the fitted values. Again, it doesn't seem too severe.

![Fitted vs. Residuals M2](https://williamscale.github.io/attachments/cps-load-prediction/fitted_resid_m2.png)

The normality assumption holds as shown by the histogram and QQ plots below.

![Hist Residuals M2](https://williamscale.github.io/attachments/cps-load-prediction/hist_resid_m2.png)

![QQ M2](https://williamscale.github.io/attachments/cps-load-prediction/qq_m2.png)

### ARIMA

Because the previous models only incorporate temperature as a feature, but the data is a time series, they do not capture trends or patterns. Therefore, I built time series models in an attempt to incorporate that information as well. To build an ARIMA (AutoRegressive Integrated Moving Average) model, I need to determine values of $p$, $d$, and $q$. A description of ARIMA can be found in [Forecasting: Principles and Practice](https://otexts.com/fpp2/non-seasonal-arima.html).

As shown below, the data does not appear to be stationary over time. There are evident changes in the demand over the training set timespan. 

![Demand Training](https://williamscale.github.io/attachments/cps-load-prediction/demand_time_training.png)

The autocorrelation function (ACF) plot reinforces this.

![Demand ACF](https://williamscale.github.io/attachments/cps-load-prediction/acf_demand.png)

To obtain stationarity, I then took the difference in demand with a lag of 1 between days. In other words, although the demand is not constant, the day-to-day difference in demand is relatively constant. This is shown both in the ACF plot, the plot over time, and via an augmented Dickey-Fuller (ADF) test ($\text{p-value}=0.01$).

![Demand Diff Training](https://williamscale.github.io/attachments/cps-load-prediction/demand_diff_time_training.png)

![Demand Diff ACF](https://williamscale.github.io/attachments/cps-load-prediction/acf_diff_demand.png)

Since the data is stationary with first differencing, I set $d=1$ in the ARIMA model. I then set $p=0$ and $q=4$ based on the ACF and partial ACF (PACF) plots above and below, respectively.

![Demand Diff PACF](https://williamscale.github.io/attachments/cps-load-prediction/pacf_diff_demand.png)

To ensure this was an appropriate choice, I also tested similar models and used the *auto.arima* function in the R forecast package. The ARIMA models run are shown in the table below.

| Model | p | d | q | Function | Equation $\left( D=\text{Demand} \right)$ |
|:-----:|:-:|:-:|:-:|:---------|:---------|
| 2.1   | 0 | 1 | 4 | Arima()  | $D_{t} - D_{t-1} = 0.14 \epsilon_{t-1} - 0.28 \epsilon_{t-2} - 0.18 \epsilon_{t-3} - 0.17 \epsilon_{t-4}$ |
| 2.2   | 0 | 1 | 5 | Arima()  | $D_{t} - D_{t-1} = 0.14 \epsilon_{t-1} - 0.28 \epsilon_{t-2} - 0.19 \epsilon_{t-3} - 0.16 \epsilon_{t-4} + 0.03 \epsilon_{t-5}$ |
| 2.3   | 0 | 1 | 3 | Arima()  | $D_{t} - D_{t-1} = 0.10 \epsilon_{t-1} - 0.31 \epsilon_{t-2} - 0.16 \epsilon_{t-3}$ |
| 2.4   | 1 | 1 | 4 | Arima()  | $D_{t} - D_{t-1} = -0.32 (D_{t-1} - D_{t-2}) + 0.46 \epsilon_{t-1} - 0.25 \epsilon_{t-2} - 0.28 \epsilon_{t-3} - 0.21 \epsilon_{t-4}$ |
| 2.5   | 0 | 1 | 4 | auto.arima(stepwise = FALSE, approximation = FALSE) | Same as Model 2.1 |

Note that with a comprehensive search by *auto.arima*, the same model is returned as the model based on the ACF/PACF plots.

### Dynamic Regression / ARIMAX

The linear regression models are able to capture effects of temperature on the energy demand, but not the past demand data, and the time series models do the opposite. Combining these methods allows both sets of data to be included. I then created dynamic regression, or ARIMAX (ARIMA with exogenous variables), models.

| Model | Description               | Equation $\left( D=\text{Demand, } T=\text{Temp} \right)$ |
|:-----:|:--------------------------|:---------|
| 3.1   | ARIMA(0, 1, 4) + Min Temp | $D_{t} - D_{t-1} = 181 (T_{\text{min, } t} - T_{\text{min, } t-1}) + 0.16 \epsilon_{t-1} - 0.28 \epsilon_{t-2} - 0.20 \epsilon_{t-3} - 0.17 \epsilon_{t-4}$ |
| 3.2   | ARIMA(0, 1, 4) + Max Temp | $D_{t} - D_{t-1} = 127 (T_{\text{max, } t} - T_{\text{max, } t-1}) + 0.16 \epsilon_{t-1} - 0.28 \epsilon_{t-2} - 0.22 \epsilon_{t-3} - 0.18 \epsilon_{t-4}$ |

### Model Comparison

Predictions were then made on the validation set using all models. 

Model 1.2 performs significantly best, using root mean squared error (RMSE) as the comparison metric. This metric penalizes larger errors more than mean absolute error (MAE), for example.

| Model | Method            | RMSE  |
|:-----:|:------------------|:-----:|
| 1.1   | Linear Regression | 5,220 |
| 1.2   | Linear Regression | 4,567 |
| 2.1   | ARIMA             | 8,141 |
| 2.2   | ARIMA             | 7,983 |
| 2.3   | ARIMA             | 7,823 |
| 2.4   | ARIMA             | 7,926 |
| 3.1   | ARIMAX            | 6,565 |
| 3.2   | ARIMAX            | 7,653 |

Then, the training and validation sets are combined and a model is re-trained on this larger dataset using the parameters from Model 1.2. The resulting model is

$$
\text{Demand} = \beta_{0} + \beta_{1} \text{Max Temp} + \beta_{2} \text{Max Temp}^{2}
$$

where $\beta_{0} = 264,671$, $\beta_{1} = -6,011$, and $\beta_{2} = 43$. All coefficients are significant with $\text{p-values} \approx 0$ and $R^{2}=0.87$. The addition of the validation set data did not affect the estimated coefficients much. The resulting regression line is shown below.

![Model](https://williamscale.github.io/attachments/cps-load-prediction/m.png)

By taking the derivative with respect to $x$ of the regression equation and setting equal to 0, the "baseline" temperature can be calculated.

$$
\begin{aligned}
\frac{\mathrm{d} x}{\mathrm{d} y} &= 2 \beta_{2} x - \beta_{1} = 0\\
&\Rightarrow x = \frac{\beta_{1}}{2 \beta_{2}} = 69.4^{\circ}\text{F}
\end{aligned}
$$

In other words, the further the temperature is from 69.4$^{\circ}$F, the higher the predicted load on a given day. The derivative is also useful in interpreting the regression equation as $2 \beta_{2} x - \beta_{1} = 97 x - 6,011$ is the change in predicted system load associated with a 1 degree temperature change at a given $x$.

## Prediction

Finally, the model was used to make predictions on the test set (November 25-December 31). On 25 days, load was overestimated and the remaining 12 days were underestimated. The overall system load in the test set was 2,143,744 MWh and the predicted load was 2,210,006 MWh, meaning there would be a surplus of 66,262 MWh if power generation decisions were based entirely on these predictions.

![Test Set](https://williamscale.github.io/attachments/cps-load-prediction/test_time.png)

The residual metrics are $\text{MAE}=3,675$ MWh, $\text{RMSE}=5,223$ MWh, and mean absolute percentage error is $\text{MAPE}=6.4\%$.

![Pct Error Hist](https://williamscale.github.io/attachments/cps-load-prediction/err_pct_hist.png)

![Pct Error](https://williamscale.github.io/attachments/cps-load-prediction/err_pct_time.png)

## Problem Formulation

To apply these predictions to the real-world, I then created the following scenario and act as CPS within the confines and assumptions I made. In other words, if CPS trusts my model blindly, given how the Texas power market works and some imposed uncertainties, will CPS profit? I have tried to note all the assumptions I made in this exercise.

I apply my predictions in the day-ahead market (DAM) and then operate in the real-time market (RTM) as needed with any energy surplus or deficit.

### CPS Capacity

For simplicity, assume there are 5 CPS power generation plants with varying parameters as shown below. Operating costs and capacities are fictional and possibly far from accurate. Capacities are set to constant for all plants except wind & solar. For those, for each operating day, I sampled from a truncated normal distribution with mean of 8,000 MWh, standard deviation of 1,000 MWh, and a max capacity of 10,000 MWh. This is an attempt to capture some of the volatility of these power sources. I also assume that the wind/solar capacities are known the day ahead. Future work on this project includes removing this assumption.

The priorities are the order that CPS uses power. Wind/solar are set to identical priorities and whichever has a higher capacity on a given day is given higher priority. I also assume that demand & capacity are constant throughout a single day. This is inaccurate since solar plants do not produce energy at night, winds vary throughout the day, and demand during the heat of the summer afternoon is much higher than on a crisp fall morning, for examples.

I believe peaking plants have very little spool up time and can be used on days CPS underestimates demand. However, for this scenario, I assume they can only be "turned on" if they are predicted to be needed on the previous day. 

| Plant        | Operating Cost [$/MWh] | Capacity [MWh]                       | Priority |
|:-------------|:----------------------:|:------------------------------------:|:--------:|
| Baseload     | 50                     | 35,000                               | 1        |
| Intermediate | 56                     | 20,000                               | 2        |
| Peaking      | 70                     | 10,000                               | 5        |
| Wind         | 45                     | $\mathcal{N} (8000, 1000, 0, 10000)$ | 3        |
| Solar        | 45                     | $\mathcal{N} (8000, 1000, 0, 10000)$ | 3        |

CPS then has a max capacity of $35000+20000+10000+10000+10000=85000$ MWh at a cost of $(50)(35000) + (56)(20000) + (70)(10000) + (45)(10000) + (45)(10000) = 4,470,000$ USD. Below is a plot of the test set capacity by power source.

![Source Area](https://williamscale.github.io/attachments/cps-load-prediction/source_area.png)

### CPS Generation & Customer Revenue
Per a [2022 Generation Utilization Update presentation](https://www.cpsenergy.com/content/dam/corporate/en/Documents/RAC/RAC%20Generation%20Utilization%20Update%20V8.pdf), CPS operates with a 13.75% buffer on energy demand. Thus, this reserve is added to each day's demand prediction.

Next, I plan for the day ahead by comparing the predicted generation needs to the capacity for each day. Below is the process for November 25, for example.

$$
\begin{aligned}
\text{predicted demand} &= 66758 \text{ MWh} \\
\text{buffer} &= 0.1375 \\
&\Rightarrow \text{generation} = 66758 \times (1 + 0.1375) = 75938 \text{ MWh}
\end{aligned}
$$

The simulated CPS capacity for November 25 is below.

| Source       | Capacity [MWh] | Cumulative Capacity [MWh] |
|:-------------|:--------------:|:-------------------------:|
| Baseload     | 35,000         | 35,000                    |
| Intermediate | 20,000         | 55,000                    |
| Wind         | 9,265          | 64,265                    |
| Solar        | 7,918          | 72,184                    |
| Peaking      | 10,000         | 82,184                    |

All of the baseload, intermediate, wind, and solar capacities are needed on this day. Max peaking capacity is not necessary, but $75938-72184=3754$ MWh should be generated from the peaking plant to fully cover the predicted demand (plus buffer). The operating cost for this day is then given by:

$$
\begin{aligned}
\text{cost} &= (35000)(50) + (20000)(56) + (9264)(45) + (7918)(45) + (3754)(70) \\
&= \$3,906,052
\end{aligned}
$$

However, on November 25, the actual demand from CPS customers was 60,190 MWh. CPS customer rates for [residential service](https://www.cpsenergy.com/content/dam/corporate/en/Documents/2024_Rate_ResidentialElectric.pdf) in non-peak periods (which the test set is in) is 0.07503 USD per kWh or 75.03 USD per MWh. For [commercial service](https://www.cpsenergy.com/content/dam/corporate/en/Documents/2024_Rate_GeneralService.pdf), the rate is 78.17 USD per MWh. I am unsure what proportion of the demand is generated by residential customers vs. commercial customers. For this exercise, I sample from a normal distribution with a mean of 0.5 and standard deviation of 0.02 and set these values as the proportion of demand due to residential customers. The commercial proportion is the remainder. On November 25, the simulated residential proportion is 50.2% with $1-0.502=0.498$ being the commercial proportion. Therefore, the revenue generated from CPS customers is given by:

$$
\text{revenue} = 60190 \times \left( (0.502)(75.03) + (0.498)(78.17) \right) = \$4,610,100
$$

Recall, though, that power was generated based on the predictions. There is then a surplus of $75938 - 60190 = 15748$ MWh that can possibly be sold by engaging in the real-time market via ERCOT. Instead of assuming there is always demand outside of the CPS service area, I made a few probabilistic assumptions. Firstly, assume there is a 50% chance there is any amount of demand off-system, i.e., $B(1, 0.5)$. Then, on days demand exists, assume the demand follows a normal distribution with mean of 10,000 MWh and standard deviation of 2,000 MWh. A snippet of the simulated off-system demand is shown below.

| Operating Day | Off-System Demand [MWh] |
|:-------------:|:-----------------------:|
| 11/25/2024    | 7,705                   |
| 11/26/2024    | 8,683                   |
| 11/27/2024    | 8,468                   |
| &#8942;       | &#8942;                 |
| 12/29/2024    | 5,224                   |
| 12/30/2024    | 7,731                   |
| 12/31/2024    | 0                       |

Simply put, the following events need to occur in order to sell excess energy:

1. Overestimate CPS customer demand.
2. Generate excess CPS customer demand.
3. Non-CPS demand exists.

For rates at which CPS can sell on the open market, I again sampled from a truncated normal distribution with a mean of 100 USD per MWh, a standard deviation of 25 USD, a minimum of 0.01 USD, and a maximum of 150 USD. Then, CPS sells all the excess energy generated that there is demand for, producing a revenue of 1,026,463 USD on November 25. In the case of underestimating CPS demand, CPS then buys power in the open market, incurring expenses. I then repeat this process for all days in the test set.

The total profit for the test set is then given by:

$$
\begin{aligned}
\text{profit} &= \text{CPS customer revenue} + \text{off-system sales} - \text{operating cost} - \text{off-system purchases} \\
&= 163,834,693 + 15,851,912 - 128,305,935 - 553,364 \\
&= \$50,827,306
\end{aligned}
$$ 

## Conclusion & Future Work

It's important to remember this model is built on actual temperatures, so the predictions are only as good as the weather forecasts. Future work could include additional features, such as humidity. Additionally, given hourly instead of daily CPS demand data, I could then incorporate actual DAM & RTM prices from ERCOT datasets. Some of my assumptions may also be invalid and require rework, but hopefully the process is reasonably accurate.